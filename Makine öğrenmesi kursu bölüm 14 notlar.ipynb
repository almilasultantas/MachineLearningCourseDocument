{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f432e53",
   "metadata": {},
   "source": [
    "Yapay Sinir Ağları (YSA)\n",
    "Artificial Neural Network (ANN)\n",
    "\n",
    "derin öğrenmenin temelini oluşturuyor \n",
    "    * Sinir bilim ve bilgisayar bilim \n",
    "    * Nöron (Neuron)\n",
    "    * Sinapsis (Synapsis)\n",
    "    * YSA Çalışma mantığı \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1021e8",
   "metadata": {},
   "source": [
    "# Nöron\n",
    "eşik fonksiyonu = threshold function\n",
    "nöronda aktivasyon fonksiyonunun önemli etkileri var \n",
    "aktivasyon kodu nöronun içinde bulunur nörana girdiler olur ve aktivasyon foksiyonuna göre bir çıktısı veya çıktıları olabilir "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb74b0b",
   "metadata": {},
   "source": [
    "# Yapay Sinir Ağlarında Katman (Layer) Kavramı\n",
    "katmanlar nöronlardan oluşuyor \n",
    "giriş katmanı input layer\n",
    "gizli katman hidden layer\n",
    "çıkış katmanı output layer\n",
    "gizli katmanda ekstra katman oluşturulabiliyor (nörondan bahsedilmiyor burada)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c920fe",
   "metadata": {},
   "source": [
    "Linearly seperable = and or \n",
    "exor is not linearly seperable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb9fe3a",
   "metadata": {},
   "source": [
    "# Grandyan Alçalış \n",
    "Gradient Descendent\n",
    "optimum noktayı bulmak için kullanılan yöntemlerdendir\n",
    "\n",
    "# Stokastik Gradyan Alçalış \n",
    "Stochastic Gradient Descendent\n",
    "optimum noktayı bulmak için kullanılan bir başka yöntemdir. Grandyan alçalışın daha gelişmiş halidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4cac8d",
   "metadata": {},
   "source": [
    "* stokastik yaklaşımda her satır sonrasında geri besleme yapılıyor\n",
    "* Batch (yığın) yaklaşımında tüm veri işleme tutulduktan sonra geri dönüş yapıyor \n",
    "* mini batch (mini yığın) yaklaşımı stokastik ve batch yönteminin arasıdır verilerin boyutlandırılması ve bu boyutlardan sonra geri besleme yapması yaklaşımıdır ayrıca mini yığın boyutu değiştirilebilir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3222c284",
   "metadata": {},
   "source": [
    "# YSA Öğrenme Algoritmaları \n",
    "    * Geri Yayılım (back propagation): hatalar geri yönde yayılır (çıkıştan girişe doğru)\n",
    "    * İleri Yayılım (forward propagation): Ağırlıklar ileri yönlü güncellenir (girişten çıkışa doğru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59383043",
   "metadata": {},
   "source": [
    "# Backward Propagation \n",
    "    * Adım 1: Bütün ağı rasgele sayılarla (sıfıra) yakın ama sıfırdan farklı) ilkendir.\n",
    "    * Adım 2: Veri kümesinden ilk satır (her öznitelik bir nöron olacak şekilde) giriş katmanından verilir.\n",
    "    * Adım 3: İleri yönlü yayılım yapılarak, YSA istenene sonucu verene kadar güncellenir.\n",
    "    * Adım 4: Gerçek ve çıktı arasında ki fark alınarak hata (error) hesaplanır.\n",
    "    * Adım 5:Geri yayılım yapılarak, her sinapsis üzerinde ki ağırlık, hatadan sorumlu olduğu miktarda değiştirilir. Değiştirilme miktarı ayrıca öğrenme oranına da bağlıdır.\n",
    "    * Adım 6: Adım 1-5 arasındaki adımları istenen sonucu elde edene kadar güncelle (Takviyeli Öğrenme (Reinforced Learning)) veya eldeki bütün verileri ilgili ağda çalıştırdıktan sonra bir seferde güncelleme yap (yığın öğrenme(batch learning))\n",
    "    * Adım 7: Bütün eğitim kümesi çalıştırıldıktan sonra bir çağ/tur (epoch) tamamlanmış olur. Aynı veri kümeleri kullanılarak çağ/tur tekrarları yapılır.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf604a0b",
   "metadata": {},
   "source": [
    "+ bias değeri \n",
    "+ learning rate: belli bir öğrenme adımının hızlı atılacağı \n",
    "+ tur(epoch): kaç tur atacağının sayısı her turda tüm verilerin üzerinden geçiyor bunun belli bir orandan sonra olumsuz etkisi olabilir bunun için bir durma noktası belirlememiz gerekmektedir çok yüksek bir değer verirsek öğrenmesine rağmen boşuna tur dönmesi demek olavak az verirsekte öğrenme tamamlanmadan sonlanması demek oluyor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba8892",
   "metadata": {},
   "source": [
    "#  Derin Öğrenme Kütüphanelerinden Bazıları \n",
    "    + PyTorch\n",
    "    + TensorFlow\n",
    "    + Caffe\n",
    "    + Keras\n",
    "    + DeepLearning4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4121f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\r\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "msg = tf.constant('Hello, TensorFlow!')\n",
    "tf.print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80509565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "veriler = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "veriler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364c1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = veriler.iloc[:,3:13].values\n",
    "Y = veriler.iloc[:,13].values\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "X[:,1] = le.fit_transform(X[:,1])\n",
    "\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "X[:,2] = le2.fit_transform(X[:,2])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ohe = ColumnTransformer([(\"ohe\", \n",
    "                         OneHotEncoder(dtype = float), \n",
    "                         [1])], remainder = \"passthrough\")\n",
    "\n",
    "X = ohe.fit_transform(X)\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb16bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66451810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.6030 - accuracy: 0.7967\n",
      "Epoch 2/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7979\n",
      "Epoch 3/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7979\n",
      "Epoch 4/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7979\n",
      "Epoch 5/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7979\n",
      "Epoch 6/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7979\n",
      "Epoch 7/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7979\n",
      "Epoch 8/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7979\n",
      "Epoch 9/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7991\n",
      "Epoch 10/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8188\n",
      "Epoch 11/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8233\n",
      "Epoch 12/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8251\n",
      "Epoch 13/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8258\n",
      "Epoch 14/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8261\n",
      "Epoch 15/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8297\n",
      "Epoch 16/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8293\n",
      "Epoch 17/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8318\n",
      "Epoch 18/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8318\n",
      "Epoch 19/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8318\n",
      "Epoch 20/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8313\n",
      "Epoch 21/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8325\n",
      "Epoch 22/50\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.4079 - accuracy: 0.8325\n",
      "Epoch 23/50\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.4075 - accuracy: 0.8340\n",
      "Epoch 24/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8331\n",
      "Epoch 25/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8336\n",
      "Epoch 26/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8339\n",
      "Epoch 27/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8346\n",
      "Epoch 28/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8342\n",
      "Epoch 29/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8339\n",
      "Epoch 30/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8343\n",
      "Epoch 31/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8352\n",
      "Epoch 32/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8349\n",
      "Epoch 33/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8351\n",
      "Epoch 34/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8369\n",
      "Epoch 35/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8337\n",
      "Epoch 36/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8354\n",
      "Epoch 37/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8349\n",
      "Epoch 38/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8364\n",
      "Epoch 39/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8351\n",
      "Epoch 40/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8351\n",
      "Epoch 41/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8345\n",
      "Epoch 42/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8349\n",
      "Epoch 43/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8363\n",
      "Epoch 44/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8340\n",
      "Epoch 45/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8355\n",
      "Epoch 46/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8358\n",
      "Epoch 47/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8346\n",
      "Epoch 48/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8357\n",
      "Epoch 49/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8351\n",
      "Epoch 50/50\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8358\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "[[0.25404057]\n",
      " [0.33171076]\n",
      " [0.15808485]\n",
      " ...\n",
      " [0.28168696]\n",
      " [0.51909465]\n",
      " [0.01679732]]\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#bizim kullanacağımız 11 tane veri var giriş katmanımız 11 iken çıkış katmanımız 1 oluyor\n",
    "\n",
    "\n",
    "classifier = Sequential() #bu satırdan sonra artık bir ysa var içinde bir şey yok daha \n",
    "classifier.add(Dense(6, kernel_initializer = \"uniform\", activation = \"relu\", input_dim = 11))#kaç tane katman vereceğimizi dense'nin içine yazıyoruz\n",
    "#ekstra gizli katman ekleme\n",
    "classifier.add(Dense(6, kernel_initializer = \"uniform\", activation = \"relu\")) #artık input gelmeyeceği için gelecek olan inputu belirtmemize gerek yok \n",
    "#çıkış katmanı \n",
    "classifier.add(Dense(1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "#toplamda 24 nöron kullanılıyor\n",
    "\n",
    "#burada nöranlar arası optimizasyon ediyoruz\n",
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "classifier.fit(X_train, y_train, epochs = 50)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(y_pred)\n",
    "#y_pred sayılarını tahmini olarak sıfır bir arasında gösteriyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a90e876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2554   63]\n",
      " [ 472  211]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred >0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
