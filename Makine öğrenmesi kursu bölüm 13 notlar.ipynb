{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f71cad",
   "metadata": {},
   "source": [
    "NLP (DDİ)\n",
    "Natural Language Processing \n",
    "Doğal Dil İşleme \n",
    "Hesaplamalı Dilbilim  / Computational Linguistic\n",
    "\n",
    "# Hedefler\n",
    "    * NLU ( Natural Language Understanding ): yazılmış olan bir metni anlamak \n",
    "    * NLG (Natural Language Genaration ): doğal dilde bir metin üretmek\n",
    "# Yaklaşımlar \n",
    "kullandığımız bilimsel olarak farklı yaklaşım çeşitleri var \n",
    "\n",
    "    * Lingusitik ( dilbilim ) yaklaşımı:doğal dil işlemeyle ilgili ilk çalışmalar burada çıkıyor cümleyi kelimelere ayırmak köklerine ayırmak kelime kullanımı dil bilimi \n",
    "    daha yavaş çalışıyor\n",
    "    daha başarılı genel olarak\n",
    "    * İstatistiksel Yaklaşımlar :metin sınıflandırmada kullanılıyor genellikle kelimenin köküne vs bakılmadan metinde olan kelime sayısına vs bakarak sınıflandırma gerçekleştirmek mümkün\n",
    "    daha hızlı çalışıyor\n",
    "    * Hibrit Yaklaşımlar : hibrit yaklaşım ise ikisinin bir arada kullanıldığı yaklaşım türü \n",
    "    \n",
    "doğal dil makina dilinden farklıdır makina 0/1 lerden anlar \n",
    "doğal dil insan dilidir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081aaee",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP) Doğal Dil İşleme (DDİ)\n",
    "    * Lingusitik (Dilbilim) Yaklaşımı \n",
    "    aşağıdan yukarı doğru ilerliyor\n",
    "        + Pragmatics (kullanımbilim): anlamın anlaşılabilmesi \n",
    "        + Semantics (Anlambilim): bunların genelde anlam bilimsel gösterimine ihtiyacımız var bütün bu alternatiflerin sonunda bir dönüştüğü ve anlam olarak bizim bu cümle ne anlatmak istediğini çıkardığımız adım\n",
    "        + Syntax (Sözdizim): bir kelimenin bütün ek ve kök ihtimalini alıp bunların cümle içinde ki yerine göre bağdaştırıyoruz \n",
    "        + Morphology(Şekilbilim): bir kelimenin ekleri ve kökleri nelerdir bu kelimenin farklı anlam ihtimalleri nelerdir bunların hepsi alternatif olarak listelenmeli \n",
    "        [+ POS-Tagging (part of Speech Tagging, Metin Parçası Etiketleme)\n",
    "        + Örüntü tanımı (isim tamlaması, sınıf tamlaması vs)\n",
    "        + Kelime anlam çıkarımı (olumlu olumsuz)]\n",
    "    * İstatistiksel Yaklaşımlar \n",
    "        + N-gram: harf harf ( yani karakter karakter) analiz edilmesi istatiksel yaklaşımdır \n",
    "        + TF-IDF: terimlerin sayılarının çıkarılması ve metinde geçme sayısı çıkarılıyor \n",
    "        + Word-Gram: kelimelerin sırası \n",
    "        + BOW (Bag of Words, Kelime Çantaları): birden fazla grup/ kategori varsa bunun sıklığının bakılarak tahmin edilmesinde kullanılıyor \n",
    "    * Hibrit Yaklaşımlar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1127a",
   "metadata": {},
   "source": [
    "# NLP Gerçek Uygulamaları \n",
    "    * Duygu Analizi (sentimental analysis)\n",
    "    * Metin Sınıflandırma (Text Categorization)\n",
    "    * Metin Özetleme (Document Summarization)\n",
    "    * Soru Cevaplama (Question Answering) \n",
    "    * Etiket Bulutları ve Anahtar Kelime Çıkarımı "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191380f0",
   "metadata": {},
   "source": [
    "# Doğal Dil İşleme İçin Bazı Kütüphaneleri\n",
    "    * NLTK : nltk.org\n",
    "    * SpaCy : spycy.io\n",
    "    * Stanford NLP\n",
    "    * OpenNLP:Apache : opennlp.apache.org\n",
    "    * Rapid Automatic Keyword Extraction (RAKE)\n",
    "    * Amueller Word Cloud \n",
    "    * Tenser Flow : Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091215a1",
   "metadata": {},
   "source": [
    "# Türkçe DDİ İçin Bazı Kütüphaneleri \n",
    "    * Zemberek (http://zembereknlp.blogspot.com/)\n",
    "    * İTÜ (https://nlp.itu.edu.tr/)\n",
    "    * Tspell(artık yok  https://tspell.sourceforge.io/hakkinda.html)\n",
    "    * Yıldız Teknik Üniveristesi (http://www.kemik.yildiz.edu.tr)\n",
    "    * Wordnet (balkanet)\n",
    "    * TrMorph (http://coltekin.net/cagri/trmorph/)\n",
    "    * TSCorpus (https://tscorpus.com/)\n",
    "    * Metu-Sabancı Tree Bank ve ITU Doğrulama Kümesi (https://web.itu.edu.tr/gulsenc/treebanks.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6891370",
   "metadata": {},
   "source": [
    "# NLP Adımları \n",
    "Bir veri kaynağında veriler(yapısal veya yapısal olmayan) geliyor sonra makine öğrenmesi modelleri çalışıyor ve sonrasında sonuçlar oluşuyor \n",
    "girdiler ve çıktılardan oluşan bi dünya \n",
    "doğal dil işlemede makine insan dilini anlayamadığı için metinleri direkt işleyemeyiz. Makinenin bunları anlayacak hale gelmesi gerekiyor yani öznitelik çıkarımı (Feature Engineering) yapılması gerekiyor. \n",
    "Makine öğrenmesinde kullanılacak verilerin sayısal olması gerekiyor. \n",
    "Öznitelik çıkarımından önce de veri ön işleme yapılmalı çünkü veri temiz olması gerekiyor (preprocessing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5c8348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.    1.0\n",
       "1                                 Crust is not good.    0.0\n",
       "2          Not tasty and the texture was just nasty.    0.0\n",
       "3  Stopped by during the late May bank holiday of...    1.0\n",
       "4  The selection on the menu was great and so wer...    1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "yorumlar = pd.read_csv(\"Restaurant_Reviews.csv\", on_bad_lines='skip')\n",
    "yorumlar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef9509b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yorumlar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fba7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "#nltk.download(\"stopwords\") \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Preprocessing(Önişleme)\n",
    "derlem = []\n",
    "uzunluk = len(yorumlar)\n",
    "for i in range(uzunluk):\n",
    "    yorum = re.sub(\"[^a-zA-Z]\",\" \", yorumlar[\"Review\"][i])\n",
    "    yorum = yorum.lower()\n",
    "    yorum = yorum.split()\n",
    "    yorum = [ps.stem(kelime) for kelime in yorum if not kelime in set(stopwords.words(\"english\"))]\n",
    "    yorum = \" \".join(yorum)\n",
    "    derlem.append(yorum)\n",
    "#print(derlem)\n",
    "#Feature Extraction (Öznitelik Çıkarımı)\n",
    "#Bag of Words (BOW)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 2000)\n",
    "X = cv.fit_transform(derlem).toarray() #bağımsız değişken\n",
    "y = yorumlar.iloc[:,1].values #bağımlı değişken\n",
    "#print(X)\n",
    "#print(y)\n",
    "import math\n",
    "for i in range(uzunluk):\n",
    "    if math.isnan(y[i]):\n",
    "        y[i]=0\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2f0c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39 36]\n",
      " [ 7 62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d81e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
